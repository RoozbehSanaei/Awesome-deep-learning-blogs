# Useful Machine Learning 

A curated list of machine Leaning concepts, impelmentations, troubleshootings, ...

## Table of Contents

<!-- MarkdownTOC depth=4 -->
- [Machine Learning Concepts](#concepts)
- [Tensorflow Implementation](#github-tutorials)

<!-- /MarkdownTOC -->
<a name="concepts" />

## Machine Learning Concepts

### Regularization

* [Batch normalization](https://towardsdatascience.com/batch-normalization-in-neural-networks-1ac91516821c) - Simple explanation of batch normalization

* [Dropout Math](https://towardsdatascience.com/simplified-math-behind-dropout-in-deep-learning-6d50f3f47275)

### Convolution

* [Different Types of Convolutions](https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215) - Visual introduction to 2D / 3D / 1x1 / Transposed / Dilated (Atrous) / Spatially Separable / Depthwise Separable / Flattened / Grouped / Shuffled Grouped Convolutions

* [Different Types of Pooling](https://machinelearningmastery.com/pooling-layers-for-convolutional-neural-networks/) Max Pooling/Average Pooling/Global Average Pooling

### Optimization

* [RMSprop,RProp,Adagrad](https://towardsdatascience.com/understanding-rmsprop-faster-neural-network-learning-62e116fcf29a)

* [Batch/Stochastic/Mini-batch gradient descent/Momentum / Nesterov accelerated gradient/Adagrad/Adadelta/RMSprop/Adam/AdaMax/Nadam/AMSGrad](https://ruder.io/optimizing-gradient-descent/index.html#nesterovacceleratedgradient)

* [Gradient descent optimization algorithms 2](http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf) 

### Activation Functions

* [ReLu,Leaky ReLu,PRelu,Elu,Selu,CRelu,Relu-6](https://medium.com/@danqing/a-practical-guide-to-relu-b83ca804f1f7)

* [GELU, SELU, ELU, ReLU](https://mlfromscratch.com/activation-functions-explained/)

* [Sigmoid, ReLU, LReLU, PReLU, RReLU, ELU, Softmax](http://laid.delanover.com/activation-functions-in-deep-learning-sigmoid-relu-lrelu-prelu-rrelu-elu-softmax/)

### Loss Functions
* [MSE,MAE,Huber Loss,Cross Entropy, Hinge Loss, Softmax,  KL-Divergence](https://www.analyticsvidhya.com/blog/2019/08/detailed-guide-7-loss-functions-machine-learning-python-code/)

* [Kullback-Leibler Divergence](https://www.countbayesie.com/blog/2017/5/9/kullback-leibler-divergence-explained) 

* [Categorical Cross-Entropy Loss, Binary Cross-Entropy Loss, Softmax Loss, Logistic Loss, Focal Loss](https://gombru.github.io/2018/05/23/cross_entropy_loss/)

<a name="github-tutorials" />

##  Implementations
### Tensorflow
* [Mask-RCNN + Keras](https://machinelearningmastery.com/how-to-train-an-object-detection-model-with-keras/) - In this tutorial, you will discover how to develop a Mask R-CNN model for kangaroo object detection in photographs

* [Yolov3 + Tensorflow 2](https://github.com/YunYang1994/tensorflow-yolov3) - Implementation of YOLO v3 object detector in Tensorflow 2.0

* [Yolov3 + Tensorflow 1](https://github.com/qqwweee/keras-yolo3) - Implementation of YOLO v3 object detector in Tensorflow 1.6
